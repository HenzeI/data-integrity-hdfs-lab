{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3b7a866b",
      "metadata": {},
      "source": [
        "# Auditoria de integridad HDFS (fsck + metricas)\n",
        "\n",
        "Este notebook esta preparado para trabajar con Docker + HDFS como en los scripts del proyecto (especialmente `scripts/30_fsck_audit.sh`).\n",
        "\n",
        "Flujo:\n",
        "1. Extraer auditorias fsck desde HDFS del contenedor `namenode`.\n",
        "2. Guardarlas en carpeta local del notebook.\n",
        "3. Leer y resumir esas auditorias.\n",
        "4. Construir tabla de metricas con `docker stats` y tiempos por fase.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0d376c5",
      "metadata": {},
      "source": [
        "## 1) Configuracion\n",
        "\n",
        "Las ejecuciones se hacen contra el contenedor Docker que tiene cliente HDFS (`namenode`).\n",
        "La descarga de auditorias se hace desde `/audit/fsck` (HDFS) hacia una carpeta local junto al notebook.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f8153b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar librerías necesarias\n",
        "!pip install pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "88866363",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN_CONTAINER: namenode\n",
            "WORKDIR: c:\\Users\\ferna\\Documents\\Proyectos\\CursoIA\\HDFSTarea\\data-integrity-hdfs-lab\\notebooks\n",
            "LOCAL_AUDIT_DIR: c:\\Users\\ferna\\Documents\\Proyectos\\CursoIA\\HDFSTarea\\data-integrity-hdfs-lab\\notebooks\\audit\\fsck\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import subprocess\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option('display.max_colwidth', 120)\n",
        "\n",
        "NN_CONTAINER = os.environ.get(\"NN_CONTAINER\", \"namenode\")\n",
        "WORKDIR = Path.cwd()\n",
        "LOCAL_AUDIT_DIR = WORKDIR / \"audit\" / \"fsck\"\n",
        "LOCAL_AUDIT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"NN_CONTAINER:\", NN_CONTAINER)\n",
        "print(\"WORKDIR:\", WORKDIR)\n",
        "print(\"LOCAL_AUDIT_DIR:\", LOCAL_AUDIT_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b58ceb18",
      "metadata": {},
      "source": [
        "## 2) Extraer auditorias desde HDFS del contenedor\n",
        "\n",
        "Si no hay auditorias locales, se ejecuta dentro del contenedor:\n",
        "- `hdfs dfs -test -d /audit/fsck`\n",
        "- `hdfs dfs -get -f /audit/fsck/* /tmp/...`\n",
        "\n",
        "Y luego se copia del contenedor al directorio local del notebook con `docker cp`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "251ccbbe",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No hay auditorias locales. Intentando extraer desde HDFS en contenedor...\n",
            "docker cp output: CompletedProcess(args='docker cp namenode:/tmp/audit_fsck_export_33360/. \"c:\\\\Users\\\\ferna\\\\Documents\\\\Proyectos\\\\CursoIA\\\\HDFSTarea\\\\data-integrity-hdfs-lab\\\\notebooks\\\\audit\\\\fsck\"', returncode=0, stdout='', stderr='')\n",
            "Extraccion completada: True\n",
            "Fechas locales detectadas: ['2026-02-13']\n"
          ]
        }
      ],
      "source": [
        "def run_cmd(cmd):\n",
        "    return subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "\n",
        "def has_local_fsck_files(local_dir: Path) -> bool:\n",
        "    return any(local_dir.glob(\"*/fsck_data.txt\"))\n",
        "\n",
        "def pull_fsck_from_container(nn_container: str, local_dir: Path) -> bool:\n",
        "    if shutil.which(\"docker\") is None:\n",
        "        print(\"docker no esta disponible en este entorno.\")\n",
        "        return False\n",
        "\n",
        "    remote_tmp = f\"/tmp/audit_fsck_export_{os.getpid()}\"\n",
        "\n",
        "    test_hdfs = run_cmd(\n",
        "        f'docker exec -i {nn_container} bash -lc \"hdfs dfs -test -d /audit/fsck\"'\n",
        "    )\n",
        "    if test_hdfs.returncode != 0:\n",
        "        print(\"No existe /audit/fsck en HDFS dentro del contenedor.\")\n",
        "        return False\n",
        "\n",
        "    prep_and_get = run_cmd(\n",
        "        f'docker exec -i {nn_container} bash -lc \"rm -rf {remote_tmp} && mkdir -p {remote_tmp} && hdfs dfs -get -f /audit/fsck/* {remote_tmp}/\"'\n",
        "    )\n",
        "    if prep_and_get.returncode != 0:\n",
        "        print(\"Fallo extrayendo auditorias con hdfs dfs -get desde el contenedor.\")\n",
        "        print(prep_and_get.stderr[:400])\n",
        "        return False\n",
        "\n",
        "    local_dir.mkdir(parents=True, exist_ok=True)\n",
        "    cp_out = run_cmd(f'docker cp {nn_container}:{remote_tmp}/. \"{str(local_dir)}\"')\n",
        "    print(\"docker cp output:\", cp_out)\n",
        "    cleanup = run_cmd(f'docker exec -i {nn_container} bash -lc \"rm -rf {remote_tmp}\"')\n",
        "\n",
        "    if cp_out.returncode != 0:\n",
        "        print(\"Fallo copiando archivos del contenedor al host con docker cp.\")\n",
        "        print(cp_out.stderr[:400])\n",
        "        return False\n",
        "\n",
        "    if cleanup.returncode != 0:\n",
        "        print(\"Aviso: no se pudo limpiar carpeta temporal remota.\")\n",
        "\n",
        "    return True\n",
        "\n",
        "if not has_local_fsck_files(LOCAL_AUDIT_DIR):\n",
        "    print(\"No hay auditorias locales. Intentando extraer desde HDFS en contenedor...\")\n",
        "    ok = pull_fsck_from_container(NN_CONTAINER, LOCAL_AUDIT_DIR)\n",
        "    print(\"Extraccion completada:\", ok)\n",
        "else:\n",
        "    print(\"Ya existen auditorias locales en\", LOCAL_AUDIT_DIR)\n",
        "\n",
        "print(\"Fechas locales detectadas:\", sorted([p.name for p in LOCAL_AUDIT_DIR.glob('*') if p.is_dir()]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1355f43f",
      "metadata": {},
      "source": [
        "## 3) Tabla de lectura de auditorias fsck\n",
        "\n",
        "Se leen los archivos extraidos (`fsck_data.txt`) y se resumen contadores de integridad.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "eb9aba5c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tabla de lectura de auditorias fsck:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dt</th>\n",
              "      <th>CORRUPT</th>\n",
              "      <th>MISSING</th>\n",
              "      <th>UNDER_REPLICATED</th>\n",
              "      <th>HEALTHY</th>\n",
              "      <th>source_file</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2026-02-13</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "      <td>c:\\Users\\ferna\\Documents\\Proyectos\\CursoIA\\HDFSTarea\\data-integrity-hdfs-lab\\notebooks\\audit\\fsck\\2026-02-13\\fsck_da...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           dt  CORRUPT  MISSING  UNDER_REPLICATED  HEALTHY  \\\n",
              "0  2026-02-13        2        4                 0     True   \n",
              "\n",
              "                                                                                                               source_file  \n",
              "0  c:\\Users\\ferna\\Documents\\Proyectos\\CursoIA\\HDFSTarea\\data-integrity-hdfs-lab\\notebooks\\audit\\fsck\\2026-02-13\\fsck_da...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def parse_fsck_text(text: str) -> dict:\n",
        "    return {\n",
        "        \"CORRUPT\": len(re.findall(r\"\\bCORRUPT\\b\", text, flags=re.IGNORECASE)),\n",
        "        \"MISSING\": len(re.findall(r\"\\bMISSING\\b\", text, flags=re.IGNORECASE)),\n",
        "        \"UNDER_REPLICATED\": len(re.findall(r\"Under replicated\", text, flags=re.IGNORECASE)),\n",
        "        \"HEALTHY\": bool(re.search(r\"Status:\\s*HEALTHY\", text, flags=re.IGNORECASE)),\n",
        "    }\n",
        "\n",
        "rows = []\n",
        "for dt_dir in sorted([p for p in LOCAL_AUDIT_DIR.glob(\"*\") if p.is_dir()]):\n",
        "    fsck_file = dt_dir / \"fsck_data.txt\"\n",
        "    if not fsck_file.exists():\n",
        "        continue\n",
        "    txt = fsck_file.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "    m = parse_fsck_text(txt)\n",
        "    m[\"dt\"] = dt_dir.name\n",
        "    m[\"source_file\"] = str(fsck_file)\n",
        "    rows.append(m)\n",
        "\n",
        "df_fsck = pd.DataFrame(rows)\n",
        "if not df_fsck.empty:\n",
        "    df_fsck = df_fsck[[\"dt\", \"CORRUPT\", \"MISSING\", \"UNDER_REPLICATED\", \"HEALTHY\", \"source_file\"]].sort_values(\"dt\")\n",
        "else:\n",
        "    df_fsck = pd.DataFrame(columns=[\"dt\", \"CORRUPT\", \"MISSING\", \"UNDER_REPLICATED\", \"HEALTHY\", \"source_file\"])\n",
        "\n",
        "print(\"Tabla de lectura de auditorias fsck:\")\n",
        "df_fsck\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2492f555",
      "metadata": {},
      "source": [
        "## 4) Tabla de metricas (tiempos/recursos)\n",
        "\n",
        "Recursos: snapshot de `docker stats`.\n",
        "Tiempos: se cargan desde `notebooks/metrics/phase_times.csv` si existe; si no, se crea plantilla para rellenar.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "d10c5e81",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Snapshot docker stats:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>container</th>\n",
              "      <th>cpu_pct</th>\n",
              "      <th>mem_used_mib</th>\n",
              "      <th>net_in_mib</th>\n",
              "      <th>net_out_mib</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>'clustera-dnnm-1</td>\n",
              "      <td>0.60</td>\n",
              "      <td>902.1</td>\n",
              "      <td>4454.40</td>\n",
              "      <td>3348.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'clustera-dnnm-3</td>\n",
              "      <td>0.52</td>\n",
              "      <td>921.2</td>\n",
              "      <td>4454.40</td>\n",
              "      <td>3624.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>'clustera-dnnm-2</td>\n",
              "      <td>0.58</td>\n",
              "      <td>764.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'namenode</td>\n",
              "      <td>0.14</td>\n",
              "      <td>490.8</td>\n",
              "      <td>2242.56</td>\n",
              "      <td>4454.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>'resourcemanager</td>\n",
              "      <td>0.51</td>\n",
              "      <td>600.8</td>\n",
              "      <td>3.14</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          container  cpu_pct  mem_used_mib  net_in_mib  net_out_mib\n",
              "0  'clustera-dnnm-1     0.60         902.1     4454.40      3348.48\n",
              "1  'clustera-dnnm-3     0.52         921.2     4454.40      3624.96\n",
              "2  'clustera-dnnm-2     0.58         764.0         NaN         1.31\n",
              "3         'namenode     0.14         490.8     2242.56      4454.40\n",
              "4  'resourcemanager     0.51         600.8        3.14          NaN"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def parse_size_to_mib(value: str) -> float:\n",
        "    value = value.strip()\n",
        "    m = re.match(r\"([0-9]+(?:\\.[0-9]+)?)\\s*([KMG]i?)?B\", value)\n",
        "    if not m:\n",
        "        return np.nan\n",
        "    num = float(m.group(1))\n",
        "    unit = (m.group(2) or \"\").upper()\n",
        "    factors = {\n",
        "        \"\": 1 / (1024 * 1024),\n",
        "        \"K\": 1 / 1024,\n",
        "        \"KI\": 1 / 1024,\n",
        "        \"M\": 1,\n",
        "        \"MI\": 1,\n",
        "        \"G\": 1024,\n",
        "        \"GI\": 1024,\n",
        "    }\n",
        "    return num * factors.get(unit, np.nan)\n",
        "\n",
        "def parse_net_to_mib(net_value: str):\n",
        "    parts = [p.strip() for p in net_value.split(\"/\")]\n",
        "    if len(parts) != 2:\n",
        "        return (np.nan, np.nan)\n",
        "    return parse_size_to_mib(parts[0]), parse_size_to_mib(parts[1])\n",
        "\n",
        "stats_cmd = \"docker stats --no-stream --format '{{.Name}},{{.CPUPerc}},{{.MemUsage}},{{.NetIO}}'\"\n",
        "res = subprocess.run(stats_cmd, shell=True, capture_output=True, text=True)\n",
        "\n",
        "stats_rows = []\n",
        "if res.returncode == 0 and res.stdout.strip():\n",
        "    for line in res.stdout.strip().splitlines():\n",
        "        name, cpu, mem_usage, net_io = [x.strip() for x in line.split(\",\", 3)]\n",
        "        mem_parts = [p.strip() for p in mem_usage.split(\"/\")]\n",
        "        mem_used_mib = parse_size_to_mib(mem_parts[0]) if mem_parts else np.nan\n",
        "        net_in_mib, net_out_mib = parse_net_to_mib(net_io)\n",
        "        cpu_pct = float(cpu.replace(\"%\", \"\").strip()) if cpu.replace(\"%\", \"\").strip() else np.nan\n",
        "        stats_rows.append({\n",
        "            \"container\": name,\n",
        "            \"cpu_pct\": cpu_pct,\n",
        "            \"mem_used_mib\": mem_used_mib,\n",
        "            \"net_in_mib\": net_in_mib,\n",
        "            \"net_out_mib\": net_out_mib,\n",
        "        })\n",
        "\n",
        "stats_df = pd.DataFrame(stats_rows)\n",
        "print(\"Snapshot docker stats:\")\n",
        "stats_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2095eb43",
      "metadata": {},
      "source": [
        "### 4.1 Generar `phase_times.csv` con medicion en tiempo real\n",
        "\n",
        "Esta celda ejecuta fases del pipeline, toma muestras de `docker stats --no-stream` cada cierto intervalo y guarda `notebooks/metrics/phase_times.csv` con:\n",
        "- `fase`\n",
        "- `duracion_seg`\n",
        "- `cpu_promedio_pct`\n",
        "- `mem_promedio_mib`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "4612948c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[metrics] Ejecutando fase: ingesta\n",
            "[metrics] ingesta: duracion=6.13s cpu_avg=0.559 mem_avg=760.63 rc=1\n",
            "[metrics] Ejecutando fase: auditoria_fsck\n",
            "[metrics] auditoria_fsck: duracion=6.1s cpu_avg=0.859 mem_avg=761.05 rc=1\n",
            "[metrics] Ejecutando fase: backup_copy\n",
            "[metrics] backup_copy: duracion=6.1s cpu_avg=1.1 mem_avg=760.97 rc=1\n",
            "[metrics] Ejecutando fase: incidente_recuperacion\n",
            "[metrics] incidente_recuperacion: duracion=6.11s cpu_avg=0.74 mem_avg=761.29 rc=1\n",
            "CSV generado: c:\\Users\\ferna\\Documents\\Proyectos\\CursoIA\\HDFSTarea\\data-integrity-hdfs-lab\\notebooks\\metrics\\phase_times.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fase</th>\n",
              "      <th>duracion_seg</th>\n",
              "      <th>cpu_promedio_pct</th>\n",
              "      <th>mem_promedio_mib</th>\n",
              "      <th>return_code</th>\n",
              "      <th>muestras</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ingesta</td>\n",
              "      <td>6.13</td>\n",
              "      <td>0.559</td>\n",
              "      <td>760.63</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>auditoria_fsck</td>\n",
              "      <td>6.10</td>\n",
              "      <td>0.859</td>\n",
              "      <td>761.05</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>backup_copy</td>\n",
              "      <td>6.10</td>\n",
              "      <td>1.100</td>\n",
              "      <td>760.97</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>incidente_recuperacion</td>\n",
              "      <td>6.11</td>\n",
              "      <td>0.740</td>\n",
              "      <td>761.29</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     fase  duracion_seg  cpu_promedio_pct  mem_promedio_mib  \\\n",
              "0                 ingesta          6.13             0.559            760.63   \n",
              "1          auditoria_fsck          6.10             0.859            761.05   \n",
              "2             backup_copy          6.10             1.100            760.97   \n",
              "3  incidente_recuperacion          6.11             0.740            761.29   \n",
              "\n",
              "   return_code  muestras  \n",
              "0            1        10  \n",
              "1            1        10  \n",
              "2            1        10  \n",
              "3            1        10  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import time\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "# Configuracion\n",
        "SAMPLE_INTERVAL_SEC = 2\n",
        "CONTAINER_FILTERS = (\"namenode\", \"resourcemanager\", \"dnnm\", \"clustera-dnnm\")\n",
        "PROJECT_ROOT = WORKDIR if (WORKDIR / \"scripts\").exists() else WORKDIR.parent\n",
        "METRICS_DIR = WORKDIR / \"metrics\"\n",
        "METRICS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "PHASE_TIMES_CSV = METRICS_DIR / \"phase_times.csv\"\n",
        "\n",
        "PHASE_COMMANDS = [\n",
        "    (\"ingesta\", \"bash scripts/20_ingest_hdfs.sh\"),\n",
        "    (\"auditoria_fsck\", \"bash scripts/30_fsck_audit.sh\"),\n",
        "    (\"backup_copy\", \"bash scripts/40_backup_copy.sh\"),\n",
        "    (\"incidente_recuperacion\", \"bash scripts/70_incident_simulation.sh && bash scripts/80_recovery_restore.sh\"),\n",
        "]\n",
        "\n",
        "def _sample_stats_once():\n",
        "    cmd = \"docker stats --no-stream --format '{{.Name}},{{.CPUPerc}},{{.MemUsage}}'\"\n",
        "    res = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    rows = []\n",
        "    if res.returncode != 0 or not res.stdout.strip():\n",
        "        return rows\n",
        "\n",
        "    for line in res.stdout.strip().splitlines():\n",
        "        name, cpu, mem_usage = [x.strip() for x in line.split(',', 2)]\n",
        "        if not any(k in name for k in CONTAINER_FILTERS):\n",
        "            continue\n",
        "        mem_used = mem_usage.split('/')[0].strip()\n",
        "        cpu_pct = float(cpu.replace('%', '').strip()) if cpu.replace('%', '').strip() else np.nan\n",
        "        rows.append({\n",
        "            \"container\": name,\n",
        "            \"cpu_pct\": cpu_pct,\n",
        "            \"mem_used_mib\": parse_size_to_mib(mem_used),\n",
        "        })\n",
        "    return rows\n",
        "\n",
        "def _run_phase_with_sampling(label, command):\n",
        "    samples = []\n",
        "    start = time.time()\n",
        "    proc = subprocess.Popen(command, shell=True, cwd=str(PROJECT_ROOT))\n",
        "\n",
        "    while proc.poll() is None:\n",
        "        samples.extend(_sample_stats_once())\n",
        "        time.sleep(SAMPLE_INTERVAL_SEC)\n",
        "\n",
        "    # Muestra final al terminar\n",
        "    samples.extend(_sample_stats_once())\n",
        "\n",
        "    end = time.time()\n",
        "    duration = round(end - start, 2)\n",
        "    rc = proc.returncode\n",
        "\n",
        "    if samples:\n",
        "        s_df = pd.DataFrame(samples)\n",
        "        cpu_avg = round(float(s_df[\"cpu_pct\"].mean()), 3)\n",
        "        mem_avg = round(float(s_df[\"mem_used_mib\"].mean()), 3)\n",
        "    else:\n",
        "        cpu_avg = np.nan\n",
        "        mem_avg = np.nan\n",
        "\n",
        "    return {\n",
        "        \"fase\": label,\n",
        "        \"duracion_seg\": duration,\n",
        "        \"cpu_promedio_pct\": cpu_avg,\n",
        "        \"mem_promedio_mib\": mem_avg,\n",
        "        \"return_code\": rc,\n",
        "        \"muestras\": len(samples),\n",
        "    }\n",
        "\n",
        "rows = []\n",
        "for phase, cmd in PHASE_COMMANDS:\n",
        "    print(f\"[metrics] Ejecutando fase: {phase}\")\n",
        "    out = _run_phase_with_sampling(phase, cmd)\n",
        "    rows.append(out)\n",
        "    print(f\"[metrics] {phase}: duracion={out['duracion_seg']}s cpu_avg={out['cpu_promedio_pct']} mem_avg={out['mem_promedio_mib']} rc={out['return_code']}\")\n",
        "\n",
        "phase_times_df = pd.DataFrame(rows)\n",
        "phase_times_df.to_csv(PHASE_TIMES_CSV, index=False)\n",
        "print(\"CSV generado:\", PHASE_TIMES_CSV)\n",
        "phase_times_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1edd96e1",
      "metadata": {},
      "source": [
        "## 5) Conclusiones y recomendaciones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "da6f6fb2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conclusiones:\n",
            "1. La ultima auditoria (2026-02-13) tiene incidencias: CORRUPT=2, MISSING=4.\n",
            "2. La fase mas lenta registrada es: ingesta.\n",
            "\n",
            "Recomendaciones:\n",
            "1. Mantener ejecucion periodica de scripts/30_fsck_audit.sh y guardar evidencia por fecha.\n",
            "2. Usar docker stats durante ingesta/backup para medir coste real de integridad.\n",
            "3. Definir frecuencia de auditoria segun criticidad de datos y coste operativo.\n"
          ]
        }
      ],
      "source": [
        "conclusiones = []\n",
        "\n",
        "if df_fsck.empty:\n",
        "    conclusiones.append(\"No se encontraron auditorias fsck locales. Ejecuta scripts/30_fsck_audit.sh y vuelve a correr la extraccion.\")\n",
        "else:\n",
        "    ult = df_fsck.sort_values(\"dt\").iloc[-1]\n",
        "    if int(ult[\"CORRUPT\"]) == 0 and int(ult[\"MISSING\"]) == 0:\n",
        "        conclusiones.append(f\"La ultima auditoria ({ult['dt']}) no muestra CORRUPT ni MISSING.\")\n",
        "    else:\n",
        "        conclusiones.append(f\"La ultima auditoria ({ult['dt']}) tiene incidencias: CORRUPT={int(ult['CORRUPT'])}, MISSING={int(ult['MISSING'])}.\")\n",
        "\n",
        "    if int(ult[\"UNDER_REPLICATED\"]) > 0:\n",
        "        conclusiones.append(\"Hay bloques under_replicated: revisar DataNodes vivos y factor de replicacion.\")\n",
        "\n",
        "if phase_times_df[\"duracion_seg\"].notna().any():\n",
        "    fase_lenta = phase_times_df.loc[phase_times_df[\"duracion_seg\"].idxmax(), \"fase\"]\n",
        "    conclusiones.append(f\"La fase mas lenta registrada es: {fase_lenta}.\")\n",
        "else:\n",
        "    conclusiones.append(\"Faltan tiempos por fase: completa notebooks/metrics/phase_times.csv para cerrar analisis de coste.\")\n",
        "\n",
        "recomendaciones = [\n",
        "    \"Mantener ejecucion periodica de scripts/30_fsck_audit.sh y guardar evidencia por fecha.\",\n",
        "    \"Usar docker stats durante ingesta/backup para medir coste real de integridad.\",\n",
        "    \"Definir frecuencia de auditoria segun criticidad de datos y coste operativo.\",\n",
        "]\n",
        "\n",
        "print(\"Conclusiones:\")\n",
        "for i, c in enumerate(conclusiones, 1):\n",
        "    print(f\"{i}. {c}\")\n",
        "\n",
        "print(\"\\nRecomendaciones:\")\n",
        "for i, r in enumerate(recomendaciones, 1):\n",
        "    print(f\"{i}. {r}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b57ef468",
      "metadata": {},
      "source": [
        "## 6) Exportación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7c3e2232",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Exportado:\n",
            "- c:\\Users\\ferna\\Documents\\Proyectos\\CursoIA\\HDFSTarea\\data-integrity-hdfs-lab\\notebooks\\fsck_resumen_notebook.csv\n",
            "- c:\\Users\\ferna\\Documents\\Proyectos\\CursoIA\\HDFSTarea\\data-integrity-hdfs-lab\\notebooks\\metricas_notebook.csv\n"
          ]
        }
      ],
      "source": [
        "out_fsck = WORKDIR / \"fsck_resumen_notebook.csv\"\n",
        "out_metrics = WORKDIR / \"metricas_notebook.csv\"\n",
        "df_fsck.to_csv(out_fsck, index=False)\n",
        "phase_times_df.to_csv(out_metrics, index=False)\n",
        "\n",
        "print(\"Exportado:\")\n",
        "print(\"-\", out_fsck)\n",
        "print(\"-\", out_metrics)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.1)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.14.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
